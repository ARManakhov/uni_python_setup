{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Скачать видео:\n",
    "https://www.youtube.com/watch?v=NdSqAAT28v0"
   ],
   "id": "7b5838cc82d94a07"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-05T04:27:38.783664Z",
     "start_time": "2024-06-05T04:26:52.475481Z"
    }
   },
   "source": [
    "import os\n",
    "!yt-dlp 'https://www.youtube.com/watch?v=NdSqAAT28v0' -o 'video.webm'"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=NdSqAAT28v0\r\n",
      "[youtube] NdSqAAT28v0: Downloading webpage\r\n",
      "[youtube] NdSqAAT28v0: Downloading ios player API JSON\r\n",
      "[youtube] NdSqAAT28v0: Downloading player 4b63a6a1\r\n",
      "[youtube] NdSqAAT28v0: Downloading m3u8 information\r\n",
      "[info] NdSqAAT28v0: Downloading 1 format(s): 244+251\r\n",
      "[download] Destination: Techno⧸Tech House Mix by DJ Haluk Arslan with Shadow Dancers [NdSqAAT28v0].f244.webm\r\n",
      "\u001B[K[download] 100% of  275.72MiB in \u001B[1;37m00:00:34\u001B[0m at \u001B[0;32m7.90MiB/s\u001B[0m0;33m00:00\u001B[0m0m\r\n",
      "[download] Destination: Techno⧸Tech House Mix by DJ Haluk Arslan with Shadow Dancers [NdSqAAT28v0].f251.webm\r\n",
      "\u001B[K[download] 100% of   74.04MiB in \u001B[1;37m00:00:07\u001B[0m at \u001B[0;32m9.59MiB/s\u001B[0m0;33m00:00\u001B[0m0m\r\n",
      "[Merger] Merging formats into \"Techno⧸Tech House Mix by DJ Haluk Arslan with Shadow Dancers [NdSqAAT28v0].webm\"\r\n",
      "Deleting original file Techno⧸Tech House Mix by DJ Haluk Arslan with Shadow Dancers [NdSqAAT28v0].f251.webm (pass -k to keep)\r\n",
      "Deleting original file Techno⧸Tech House Mix by DJ Haluk Arslan with Shadow Dancers [NdSqAAT28v0].f244.webm (pass -k to keep)\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Средствами библиотек Python извлечь из видео кадры (в оригинале извлекался каждый третий кадр).",
   "id": "4e4c361a8c1ebfc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T11:28:17.474517Z",
     "start_time": "2024-06-05T11:28:17.280931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "vidcap = cv2.VideoCapture('video.webm')"
   ],
   "id": "2c0f6f5aed1a6954",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T05:09:30.703731Z",
     "start_time": "2024-06-05T05:02:54.100974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('video_frames', exist_ok=True)\n",
    "\n",
    "frame_margin = 3\n",
    "\n",
    "success, image = vidcap.read()\n",
    "count = 1\n",
    "alt_count = 1\n",
    "while success:\n",
    "    if count % frame_margin == 0:\n",
    "        cv2.imwrite(os.path.join(\"video_frames\", f\"image_{alt_count}.jpg\"), image)\n",
    "        alt_count += 1\n",
    "    success, image = vidcap.read()\n",
    "    count += 1\n"
   ],
   "id": "2a56d9eb4e81b6f4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Средствами библиотек Python преобразовать разрешение кадров 1920x1080 -> 96x54 (можно другое соотношение).",
   "id": "da1fbb51ea14dfb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T11:32:59.552392Z",
     "start_time": "2024-06-05T11:30:47.715177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2, os\n",
    "\n",
    "os.makedirs('video_frames_small', exist_ok=True)\n",
    "\n",
    "for image_name in os.listdir('video_frames'):\n",
    "    image = cv2.imread(os.path.join('video_frames', image_name))\n",
    "    image = cv2.resize(image, (96, 54))\n",
    "    cv2.imwrite(os.path.join(\"video_frames_small\", image_name), image)"
   ],
   "id": "c23359396f3f433f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. Средствами библиотек Python перевести в черно-белое изображение (белый фон, черная фигура)",
   "id": "2b8f7a63edf3145d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T11:33:11.191351Z",
     "start_time": "2024-06-05T11:32:59.553052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "os.makedirs('video_frames_bw', exist_ok=True)\n",
    "for image_name in os.listdir('video_frames_small'):\n",
    "    image = cv2.imread(os.path.join('video_frames_small', image_name), 1)\n",
    "    tmp = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, alpha = cv2.threshold(tmp, 50, 255, cv2.THRESH_BINARY)\n",
    "    image[alpha.astype(bool), :] = [255, 255, 255]\n",
    "    cv2.imwrite(os.path.join(\"video_frames_bw\", image_name), image)"
   ],
   "id": "a9d04b94ef2dd600",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5. Обучить в Pytorch автоэнкодер (с помощью полносвязных слоев или, как в видео, сверточных) так, чтобы каждое изображение кодировалось вектором длины 128.",
   "id": "f7557954ccecd5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T12:42:05.844142Z",
     "start_time": "2024-06-05T12:42:04.720254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np"
   ],
   "id": "e3342784f3ce2d59",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T12:42:05.862202Z",
     "start_time": "2024-06-05T12:42:05.845249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class DanceImageDataset(Dataset):\n",
    "    def __init__(self, base_path):\n",
    "        self.base_path = base_path\n",
    "        self.image_names = os.listdir(base_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = cv2.imread(os.path.join(self.base_path, self.image_names[index]), cv2.COLOR_BGR2GRAY)\n",
    "        one_channel_image = (image[:, :, 1]\n",
    "                             .reshape(96 * 54)\n",
    "                             .astype(np.float32))  # так как по факту у нас и так все чб, можно взять один канал\n",
    "        return one_channel_image, one_channel_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "\n",
    "dataset = DanceImageDataset('video_frames_bw')\n",
    "loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                     batch_size=256,\n",
    "                                     shuffle=True)"
   ],
   "id": "f6c4fceaa6f36e54",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T12:42:05.866518Z",
     "start_time": "2024-06-05T12:42:05.863060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creating a PyTorch class\n",
    "# 28*28 ==> 9 ==> 28*28\n",
    "class AE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(96 * 54, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 128),\n",
    "        )\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(128, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(256, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 96 * 54)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ],
   "id": "98260af0d7a2da6e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T12:42:06.637434Z",
     "start_time": "2024-06-05T12:42:05.867168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = AE()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=1e-1,\n",
    "                             weight_decay=1e-8)"
   ],
   "id": "d4ea7afad0a0d64c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-05T13:23:08.005332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gc\n",
    "\n",
    "epochs = 20\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    print(f'epoch {epoch} started')\n",
    "    for (image, _) in loader:\n",
    "        image = image.to(device)\n",
    "        # Output of Autoencoder\n",
    "        reconstructed = model(image)\n",
    "\n",
    "        # Calculating the loss function\n",
    "        loss = loss_function(reconstructed, image)\n",
    "\n",
    "        # The gradients are set to zero,\n",
    "        # the gradient is computed and stored.\n",
    "        # .step() performs parameter update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Storing the losses in a list for plotting\n",
    "        losses.append(loss.cpu().detach())\n",
    "        # del loss\n",
    "    torch.cuda.empty_cache()\n",
    "    # gc.collect()\n",
    "\n",
    "# Defining the Plot Style\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "# Plotting the last 100 values\n",
    "plt.plot(losses[-100:])"
   ],
   "id": "eda7081cb3be287c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 started\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-05T13:21:21.417046Z",
     "start_time": "2024-06-05T13:21:20.986368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, item in enumerate(image):\n",
    "  # Reshape the array for plotting\n",
    "  item = item.reshape(-1, 54, 96)\n",
    "  plt.subplot(2,1,1)\n",
    "  plt.imshow(item[0])\n",
    " \n",
    "for i, item in enumerate(reconstructed):\n",
    "  item = item.detach().reshape(-1, 54, 96)\n",
    "  plt.subplot(2,1,2)\n",
    "  plt.imshow(item[0])\n"
   ],
   "id": "3184bb20a79b8997",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m   item \u001B[38;5;241m=\u001B[39m item\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m54\u001B[39m, \u001B[38;5;241m96\u001B[39m)\n\u001B[1;32m      4\u001B[0m   plt\u001B[38;5;241m.\u001B[39msubplot(\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m----> 5\u001B[0m   \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitem\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, item \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(reconstructed):\n\u001B[1;32m      8\u001B[0m   item \u001B[38;5;241m=\u001B[39m item\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m54\u001B[39m, \u001B[38;5;241m96\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/prog/python_projects/uni_python_setup/.venv/lib/python3.12/site-packages/matplotlib/pyplot.py:3358\u001B[0m, in \u001B[0;36mimshow\u001B[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001B[0m\n\u001B[1;32m   3337\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mimshow)\n\u001B[1;32m   3338\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mimshow\u001B[39m(\n\u001B[1;32m   3339\u001B[0m     X: ArrayLike \u001B[38;5;241m|\u001B[39m PIL\u001B[38;5;241m.\u001B[39mImage\u001B[38;5;241m.\u001B[39mImage,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3356\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   3357\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m AxesImage:\n\u001B[0;32m-> 3358\u001B[0m     __ret \u001B[38;5;241m=\u001B[39m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3359\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3360\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcmap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcmap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3361\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnorm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3362\u001B[0m \u001B[43m        \u001B[49m\u001B[43maspect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maspect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3363\u001B[0m \u001B[43m        \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3364\u001B[0m \u001B[43m        \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3365\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3366\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvmax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3367\u001B[0m \u001B[43m        \u001B[49m\u001B[43morigin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morigin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3368\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3369\u001B[0m \u001B[43m        \u001B[49m\u001B[43minterpolation_stage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation_stage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3370\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilternorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilternorm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3371\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilterrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilterrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3372\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3373\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3374\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3375\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3376\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3377\u001B[0m     sci(__ret)\n\u001B[1;32m   3378\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m __ret\n",
      "File \u001B[0;32m~/Documents/prog/python_projects/uni_python_setup/.venv/lib/python3.12/site-packages/matplotlib/__init__.py:1465\u001B[0m, in \u001B[0;36m_preprocess_data.<locals>.inner\u001B[0;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1462\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m   1463\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(ax, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1464\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1465\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43max\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1467\u001B[0m     bound \u001B[38;5;241m=\u001B[39m new_sig\u001B[38;5;241m.\u001B[39mbind(ax, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1468\u001B[0m     auto_label \u001B[38;5;241m=\u001B[39m (bound\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mget(label_namer)\n\u001B[1;32m   1469\u001B[0m                   \u001B[38;5;129;01mor\u001B[39;00m bound\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(label_namer))\n",
      "File \u001B[0;32m~/Documents/prog/python_projects/uni_python_setup/.venv/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5759\u001B[0m, in \u001B[0;36mAxes.imshow\u001B[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001B[0m\n\u001B[1;32m   5756\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m aspect \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5757\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_aspect(aspect)\n\u001B[0;32m-> 5759\u001B[0m \u001B[43mim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5760\u001B[0m im\u001B[38;5;241m.\u001B[39mset_alpha(alpha)\n\u001B[1;32m   5761\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m im\u001B[38;5;241m.\u001B[39mget_clip_path() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5762\u001B[0m     \u001B[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/prog/python_projects/uni_python_setup/.venv/lib/python3.12/site-packages/matplotlib/image.py:723\u001B[0m, in \u001B[0;36m_ImageBase.set_data\u001B[0;34m(self, A)\u001B[0m\n\u001B[1;32m    721\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(A, PIL\u001B[38;5;241m.\u001B[39mImage\u001B[38;5;241m.\u001B[39mImage):\n\u001B[1;32m    722\u001B[0m     A \u001B[38;5;241m=\u001B[39m pil_to_array(A)  \u001B[38;5;66;03m# Needed e.g. to apply png palette.\u001B[39;00m\n\u001B[0;32m--> 723\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_normalize_image_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    724\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_imcache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    725\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstale \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/prog/python_projects/uni_python_setup/.venv/lib/python3.12/site-packages/matplotlib/image.py:686\u001B[0m, in \u001B[0;36m_ImageBase._normalize_image_array\u001B[0;34m(A)\u001B[0m\n\u001B[1;32m    680\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    681\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_normalize_image_array\u001B[39m(A):\n\u001B[1;32m    682\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    683\u001B[0m \u001B[38;5;124;03m    Check validity of image-like input *A* and normalize it to a format suitable for\u001B[39;00m\n\u001B[1;32m    684\u001B[0m \u001B[38;5;124;03m    Image subclasses.\u001B[39;00m\n\u001B[1;32m    685\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 686\u001B[0m     A \u001B[38;5;241m=\u001B[39m \u001B[43mcbook\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msafe_masked_invalid\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    687\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m A\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m np\u001B[38;5;241m.\u001B[39muint8 \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39mcan_cast(A\u001B[38;5;241m.\u001B[39mdtype, \u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msame_kind\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    688\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage data of dtype \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mA\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m cannot be \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    689\u001B[0m                         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconverted to float\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/prog/python_projects/uni_python_setup/.venv/lib/python3.12/site-packages/matplotlib/cbook.py:733\u001B[0m, in \u001B[0;36msafe_masked_invalid\u001B[0;34m(x, copy)\u001B[0m\n\u001B[1;32m    732\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msafe_masked_invalid\u001B[39m(x, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 733\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msubok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    734\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m x\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39misnative:\n\u001B[1;32m    735\u001B[0m         \u001B[38;5;66;03m# If we have already made a copy, do the byteswap in place, else make a\u001B[39;00m\n\u001B[1;32m    736\u001B[0m         \u001B[38;5;66;03m# copy with the byte order swapped.\u001B[39;00m\n\u001B[1;32m    737\u001B[0m         \u001B[38;5;66;03m# Swap to native order.\u001B[39;00m\n\u001B[1;32m    738\u001B[0m         x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mbyteswap(inplace\u001B[38;5;241m=\u001B[39mcopy)\u001B[38;5;241m.\u001B[39mview(x\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mnewbyteorder(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mN\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "File \u001B[0;32m~/Documents/prog/python_projects/uni_python_setup/.venv/lib/python3.12/site-packages/torch/_tensor.py:1087\u001B[0m, in \u001B[0;36mTensor.__array__\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m   1085\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(Tensor\u001B[38;5;241m.\u001B[39m__array__, (\u001B[38;5;28mself\u001B[39m,), \u001B[38;5;28mself\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m   1086\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1087\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1088\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1089\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnumpy()\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mTypeError\u001B[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "6. Перевести все изображения в последовательность 128-мерных векторов.\n",
    "7. Обучить рекуррентную нейронную сеть (подобрать параметры самостоятельно) предсказывать по текущему следующий вектор.\n",
    "8. С помощью обученной сети сгенерировать последовательность векторов.\n",
    "9. Перевести с помощью декодера последовательность векторов в последовательность кадров.\n",
    "10. Средствами библиотек Python преобразовать кадры в видео."
   ],
   "id": "31ce91dd89f12c88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "eac4b035ed7c0684",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
